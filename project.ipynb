{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting game prices</h1>\n",
    "<h5 style=\"margin-left: 2rem\">By: Elad Ben-Haim, Shalev Hadar</h5>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>נושא המחקר</h4>\n",
    "<table dir=\"rtl\">\n",
    "    <tr>\n",
    "        <th>\n",
    "            נושא המחקר\n",
    "        </th>\n",
    "        <th>\n",
    "            פירוט הנושא\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        האם ניתן לחזות מחיר של משחק בעוד x זמן?\n",
    "        </td>\n",
    "        <td>\n",
    "        מתי הכי ישתלם לקנות את המשחק בעתיד\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        האם ניתן לחזור מתי למוכר הכי משתלם לעשות מבצע על המשחק?\n",
    "        </td>\n",
    "        <td>\n",
    "        מתי הכי כדאי למוכר לעשות מבצע כדי להביא עוד שחקנים ולהמשיך למכור עם הרווח הגדול ביותר\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>נתוני המחקר ודרכי ניתוח</h4>\n",
    "<table dir=\"rtl\">\n",
    "    <tr>\n",
    "        <th>\n",
    "            נתוני המחקר & דרכי ניתוח\n",
    "        </th>\n",
    "        <th>\n",
    "             ואיך ננתח אותם\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "\t\tפירוט הנתונים: פרטים פיננסיים הוא נמכר בזמן X ואז לחזות בכמה הוא ימכר בזמן Y ובנוסף פרטים על המשחק - כמו שם, ז'אנר פופולריות וכו'.\n",
    "        </td>\n",
    "        <td>\n",
    "            <p style=\"font-size: 1.1rem\">\n",
    "                נשתמש ב-Crawling על אתר isThereAnyDeal(Fig.3)<br/>\n",
    "                כדי לא לקבל הודעת שגיאה על שימוש יתר, נשתמש ב-PROXY כדי לא להחסם ע\"י isThereAnyDeal<br/>\n",
    "                ונייבא משם את כל המידע הדרוש כדי לחזות את המחיר של משחק בעוד X זמן מסוים.<br/>\n",
    "                ראינו שלכל משחק קיים באיזור ה1000+ (Fig.2) רשומות של log (Fig.1) של המחיר שלו ביחס לזמן, ולחנות בה הוא נמכר ואת העלייה\\ירידה במחיר של המשחק ביחד ללוג הקודם.<br/>\n",
    "                בעזרת STEAM API נוציא את ז'אנר המשחק, שנת הייצור ועוד פרטים מורכבים יותר על המשחק עצמו<br/>\n",
    "                ולבסוף נצרף לכל לוג את פרטי המשחק ונקבל Dataset בגודל n = כמות המשחקים, x = כמות הלוגים, כלומר n*x<br/>\n",
    "                אנחנו מעוניינים כרגע לקחת את 100 המשחקים הראשונים ולפי מה שראינו כמות הלוגים בדרך כלל היא לפחות 1000 אז נקבל בסביבות ה100,000+ רשומות.<br/>\n",
    "            </p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "\t\tדרכי ניתוח: נשתמש בכלים שלמדנו במהלך הקורס לעבד\\ללמוד מהנתונים כמה מידע שאנו צריכים למטרה זו\n",
    "        </td>\n",
    "        <td>\n",
    "            <p style=\"font-size: 1.1rem\">\n",
    "                ננתח את הDataFrame, בעזרת טבלאות יחסי משתנים, סטטיסטיקות, ולבסוף ננסה ללמד מכונה שתחזה את התאריך של המחיר הזול ביותר בשנה מסוימת, ואת המחיר אשר יביא את כמות המכירות הגדול ביותר\n",
    "            </p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br/>\n",
    "<table style=\"width:100%;grid-template-rows: 1fr 1fr 1fr;\">\n",
    "<tr>\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"images\\log_table_for_ds3.png\" alt=\"Is there any deal log table\">\n",
    "            <figcaption>Fig.1 - The main crawled data source</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"images\\number_of_logs_for_ds3.png\" alt=\"Example for number of rows in a typical game\">\n",
    "            <figcaption>Fig.2 - Example for number of rows in a typical game (Dark souls 3) </figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"images\\is_there_any_deal_site_example_ds3.png\" alt=\"Is there any deal game page\">\n",
    "            <figcaption>Fig.3 - IsThereAnyDeal game page</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Global functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_response(url: str, proxy: str) -> requests.Response:\n",
    "    if (proxy is not None):\n",
    "        return requests.get(url, proxies={\"http\": proxy, \"https\":proxy})\n",
    "    else\n",
    "        return requests.get(url)\n",
    "\n",
    "def get_response_as_beautiful_soup(htmlText: requests.Response) -> BeautifulSoup:\n",
    "    return BeautifulSoup(htmlText.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Defining proxies for scraping</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Get proxy list response html website</h5>\n",
    "<h6>get the html as response object instead of getting the html again and again</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the html of the proxy list website\n",
    "def get_proxy_list_html() -> requests.Response:\n",
    "    # Website to get free proxies\n",
    "    return get_html_response('https://free-proxy-list.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies_response = get_proxy_list_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Scrape proxy ip addresses</h5>\n",
    "<h6>gets the ip addresses as a list, shuffles them and returns an iterator to cycle through when making scrape requests</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy_list() -> itertools.cycle:\n",
    "    soup = get_response_as_beautiful_soup(proxies_response)\n",
    "    proxy_soup_list = soup.select('#list > div > div.table-responsive > div > table > tbody > tr')\n",
    "    proxy_list = list(map(lambda i: i.select('td:nth-child(1)')[0].text + ':' + i.select('td:nth-child(2)')[0].text, proxy_soup_list))\n",
    "    random.shuffle(proxy_list)\n",
    "    return itertools.cycle(proxy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_list = get_proxy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxied(url: str) -> requests.Response:\n",
    "    i = 0\n",
    "    while(i < len(proxy_list) - 1):\n",
    "        try:\n",
    "            response = get_html_response(url)\n",
    "            proxy_list = next(proxy_list)\n",
    "            return response\n",
    "        except:\n",
    "            i += 1\n",
    "\n",
    "    raise RuntimeError('None of the proxies provided work.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scrape isThereAnyDeal website</h4>\n",
    "<h6>Steps:</h6>\n",
    "<ol>\n",
    "<li>Crawl list of top 100 trending games</li>\n",
    "<li>For each game:</li>\n",
    "<ul>\n",
    "    <li>get the game details from steam API using \"appId\" scraped either from PC Gaming Wiki or Steam Ladder links</li>\n",
    "    <li>mine price Log history on isThereAnyDeal</li>\n",
    "    <li>mine Number of sales of the game</li>\n",
    "<ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Get list of 100 top trending games</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_there_any_deal_games_response() -> requests.Response:\n",
    "    filteredUrl = 'https://isthereanydeal.com/?by=trending:desc#/filter:&releaseyear/2010/2021,&pl/windows,&drm/steam,steam,-dlc,-type/6,-type/8,-type/7;/options:all'\n",
    "    return get_proxied(filteredUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_there_any_deal_games_response = get_is_there_any_deal_games_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_links():\n",
    "    soup = get_response_as_beautiful_soup(is_there_any_deal_games_response)\n",
    "    print(soup.select(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_links = get_game_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_details_response():\n",
    "    return get_html_response(\"https://isthereanydeal.com/game/deadbydaylight/history/#/chart:low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_details_response = get_game_details_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_details():\n",
    "    soup = get_response_as_beautiful_soup(game_details_response)\n",
    "    return soup.select(\"#pageContainer > script:nth-child(9)\")\n",
    "\n",
    "gamedetails = str(get_game_details()[0])\n",
    "m = re.findall('JSON\\.stringify\\((.*?)\\)', gamedetails)\n",
    "# print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Used Resources</h3>\n",
    "<dl>\n",
    "    <dt>Scraping</dt>\n",
    "    <dd>\n",
    "        <a href=\"https://isthereanydeal.com/game/reddeadredemptionii/info/\">\n",
    "            <b>Is-There-Any-Deal website</b> For scraping cost history and more financial details\n",
    "        </a>\n",
    "    </dd>\n",
    "    <dd>\n",
    "        <a href=\"https://www.geeksforgeeks.org/web-scraping-without-getting-blocked/\">\n",
    "            <b>Using Proxies to avoiding getting blocked</b>\n",
    "        </a>\n",
    "    </dd>\n",
    "    <dd>\n",
    "        <a href=\"https://wiki.teamfortress.com/wiki/User:RJackson/StorefrontAPI#App_info\">\n",
    "            <b>Steam StoreFront API</b> Limited to 100,000 requests per day, and no more than 10 per second\n",
    "        </a>\n",
    "    </dd>\n",
    "    <dd>\n",
    "        <a href=\"https://store.steampowered.com/api/appdetails\">Steam API for Game Metadata - https://store.steampowered.com/api/appdetails?appids=1091500</a>\n",
    "    </dd>\n",
    "</dl>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79d14381c615de0483739fde38a1fe3340d940b640c68fad7128c060c0741248"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
